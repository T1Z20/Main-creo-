{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "from torch.utils.data import DataLoader \n",
    "from chess import pgn \n",
    "from tqdm import tqdm \n",
    "\n",
    "from Entrada import create_input_for_nn, encode_moves\n",
    "from Modelo import ChessModel\n",
    "from Dataset import ChessDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 27/79 [02:14<04:18,  4.97s/it]\n"
     ]
    }
   ],
   "source": [
    "def load_pgn(file_path):\n",
    "    games = []\n",
    "    with open(file_path, 'r') as pgn_file:\n",
    "        while True:\n",
    "            game = pgn.read_game(pgn_file)\n",
    "            if game is None:\n",
    "                break\n",
    "            games.append(game)\n",
    "    return games\n",
    "\n",
    "files = [file for file in os.listdir(\"../data/pgn/\") if file.endswith(\".pgn\")]\n",
    "LIMIT_OF_FILES = min(len(files), 28)\n",
    "games = []\n",
    "i = 1\n",
    "\n",
    "for file in tqdm(files):\n",
    "    games.extend(load_pgn(f\"../data/pgn/{file}\"))\n",
    "    if i >= LIMIT_OF_FILES:\n",
    "        break\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAMES PARSED: 41570\n"
     ]
    }
   ],
   "source": [
    "print(f\"GAMES PARSED: {len(games)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones auxiliares\n",
    "def process_batch(games_batch):\n",
    "    X_batch, y_batch = create_input_for_nn(games_batch)\n",
    "    y_batch, move_to_int = encode_moves(y_batch)\n",
    "    return torch.tensor(X_batch, dtype=torch.float32), torch.tensor(y_batch, dtype=torch.long), move_to_int\n",
    "\n",
    "def load_games_in_batches(batch_size, total_games):\n",
    "    for i in range(0, total_games, batch_size):\n",
    "        yield games[i:i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, batch, loss, filename):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "        'batch': batch\n",
    "    }, filename)\n",
    "\n",
    "def load_checkpoint(model, optimizer, filename):\n",
    "    checkpoint = torch.load(filename)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    return checkpoint['epoch'], checkpoint['batch'], checkpoint['loss']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Configuración\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##CONVIRTIENDO LOS DATOS EN TENSORES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000  # Reducido para menor uso de memoria\n",
    "total_games = len(games)\n",
    "num_epochs = 3\n",
    "checkpoint_interval = 5000  # Guardar cada 5000 batches\n",
    "checkpoint_dir = 'checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_games = games[:batch_size]\n",
    "_, y_sample, move_to_int = process_batch(sample_games)\n",
    "num_classes = len(move_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChessModel(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el último checkpoint si existe\n",
    "last_checkpoint = max([f for f in os.listdir(checkpoint_dir) if f.startswith('checkpoint_')], default=None)\n",
    "start_epoch = 0\n",
    "start_batch = 0\n",
    "if last_checkpoint:\n",
    "    start_epoch, start_batch, _ = load_checkpoint(model, optimizer, os.path.join(checkpoint_dir, last_checkpoint))\n",
    "    print(f\"Resuming from checkpoint: {last_checkpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Tiza\\Desktop\\Work\\Proyectos\\IA\\AlphaSJ\\Main(creo)\\Entranamiento copy.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tiza/Desktop/Work/Proyectos/IA/AlphaSJ/Main%28creo%29/Entranamiento%20copy.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tiza/Desktop/Work/Proyectos/IA/AlphaSJ/Main%28creo%29/Entranamiento%20copy.ipynb#X13sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Tiza/Desktop/Work/Proyectos/IA/AlphaSJ/Main%28creo%29/Entranamiento%20copy.ipynb#X13sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mclip_grad_norm_(model\u001b[39m.\u001b[39;49mparameters(), max_norm\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tiza/Desktop/Work/Proyectos/IA/AlphaSJ/Main%28creo%29/Entranamiento%20copy.ipynb#X13sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tiza/Desktop/Work/Proyectos/IA/AlphaSJ/Main%28creo%29/Entranamiento%20copy.ipynb#X13sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:76\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[1;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39mfor\u001b[39;00m ((device, _), [grads]) \u001b[39min\u001b[39;00m grouped_grads\u001b[39m.\u001b[39mitems():\n\u001b[0;32m     75\u001b[0m     \u001b[39mif\u001b[39;00m (foreach \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m foreach) \u001b[39mand\u001b[39;00m _has_foreach_support(grads, device\u001b[39m=\u001b[39mdevice):\n\u001b[1;32m---> 76\u001b[0m         torch\u001b[39m.\u001b[39;49m_foreach_mul_(grads, clip_coef_clamped\u001b[39m.\u001b[39;49mto(device))  \u001b[39m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     \u001b[39melif\u001b[39;00m foreach:\n\u001b[0;32m     78\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mforeach=True was passed, but can\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mt use the foreach API on \u001b[39m\u001b[39m{\u001b[39;00mdevice\u001b[39m.\u001b[39mtype\u001b[39m}\u001b[39;00m\u001b[39m tensors\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    batch_count = 0\n",
    "    \n",
    "    for games_batch in load_games_in_batches(batch_size, total_games):\n",
    "        if epoch == start_epoch and batch_count < start_batch:\n",
    "            batch_count += 1\n",
    "            continue\n",
    "        \n",
    "        X_batch, y_batch, _ = process_batch(games_batch)\n",
    "        \n",
    "        dataset = ChessDataset(X_batch, y_batch)\n",
    "        dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        batch_count += 1\n",
    "        \n",
    "        if batch_count % checkpoint_interval == 0:\n",
    "            checkpoint_filename = os.path.join(checkpoint_dir, f'checkpoint_epoch{epoch}_batch{batch_count}.pth')\n",
    "            save_checkpoint(model, optimizer, epoch, batch_count, running_loss / batch_count, checkpoint_filename)\n",
    "            print(f\"Checkpoint saved: {checkpoint_filename}\")\n",
    "        \n",
    "        # Liberar memoria\n",
    "        del X_batch, y_batch, dataset, dataloader\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    minutes, seconds = divmod(epoch_time, 60)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / batch_count:.4f}, Time: {int(minutes)}m{int(seconds)}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
